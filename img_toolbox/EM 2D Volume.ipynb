{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creation of a dense EM sub-volume along with its corresponding mask volume.**\n",
    "\n",
    "The notebook works through the following steps:\n",
    "\n",
    "* Crop a denser sub-volume from EM (crop the label accordingly)\n",
    "* Upsample the EM along x-y plane. create a zero volume with the same size as the upsampled\n",
    "* Take 128x128 patches from the x-y plane in slides window order\n",
    "* Put the patches in the corresponding coordinate in the zero volume\n",
    "* upsample the label volume with NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image manipulation\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# data format handling\n",
    "import tifffile\n",
    "import h5py\n",
    "\n",
    "# utility, visualization, and path handling \n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# system configurations handling\n",
    "from yacs.config import CfgNode as CN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_C = CN()\n",
    "\n",
    "# paths to the source images, corresponding segmentation masks and crop masks\n",
    "#_C.TIFIMG = '/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/dorsal_crop_3D_full/trainA/full_volume_em_3D_70_75_80.tif'\n",
    "#_C.H5MASK = '/n/pfister_lab2/Lab/vcg_connectomics/EM/zebraFish/benchmark/mask_gt.h5'\n",
    "#_C.H5SEGGT = '/n/pfister_lab2/Lab/vcg_connectomics/EM/zebraFish/benchmark/seg_gt.h5'\n",
    "\n",
    "_C.TIFIMG = '/n/pfister_lab2/Lab/leander/cerberus/ccgan/datasets/dorsal_crop_3D_255_512/testA/em_3D_255_512_512.tif'\n",
    "#_C.H5MASK = '/n/pfister_lab2/Lab/vcg_connectomics/EM/zebraFish/benchmark/mask_gt.h5'\n",
    "_C.H5SEGGT = '/n/pfister_lab2/Lab/leander/cerberus/ccgan/datasets/dorsal_crop_3D_255_512/gt_seg_mask/seg_3D_255_512_512.tif'\n",
    "\n",
    "\n",
    "#_C.SAVEA = '/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/dorsal_crop_3D_full_tiled/testA'\n",
    "_C.SAVEAGT = '/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/submission_255_512_512/gt_seg_mask'\n",
    "_C.SAVEA = '/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/submission_255_512_512/testA'\n",
    "\n",
    "_C.SCALE = [1,1] \n",
    "_C.BLOCKSIZE = [128,128]\n",
    "#_C.IMG_SHAPE = (1105, 1235)\n",
    "_C.IMG_SHAPE = (512, 512)\n",
    "#_C.IMG_LEN = 132\n",
    "_C.IMG_LEN = 255\n",
    "\n",
    "# specify how many patches should be discarded\n",
    "_C.DISCARD_PATCH_LEFT_RIGHT = (0,0)\n",
    "_C.DISCARD_PATCH_TOP_BOT = (0,0)\n",
    "# specify how which slices should be discarded\n",
    "_C.DISCARD_SLICE_TOP_BOT = (0,0)\n",
    "\n",
    "_C.FILTER = False\n",
    "_C.RAW = True # no filtering and no normalization of the segmentation masks\n",
    "\n",
    "_C.NRSAVEIMG = float(\"inf\")  # number of image blocks that should be saved\n",
    "\n",
    "def get_cfg_defaults():\n",
    "  \"\"\"Get a yacs CfgNode object with default values for my_project.\"\"\"\n",
    "  # Return a clone so that the defaults will not be altered\n",
    "  # This is for the \"local variable\" use pattern\n",
    "  return _C.clone()\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "#cfg.merge_from_file(\"./configs/base_setup.yaml\")\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H5 Image Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_h5s(img_list, img_file_name, size=None):\n",
    "    \"\"\" Take a list of images and writes them to a h5 file\n",
    "    \n",
    "        Args:\n",
    "            img_list: List of images that should be written to the h5-file\n",
    "            img_file_name: Name for the h5-file\n",
    "            size: Size to which the images are resized, has to be an int tuple\n",
    "    \"\"\"\n",
    "    \n",
    "    # open a h5-file for writing\n",
    "    with h5py.File(img_file_name, \"w\") as img_patches:\n",
    "        \n",
    "        # create the dataset specifing key and shape of the dataset\n",
    "        if size is not None:\n",
    "            assert isinstance(size, tuple)\n",
    "            img_patches = img_patches.create_dataset('main',shape=(len(img_list),size[0],size[1]), dtype=int)\n",
    "        else:\n",
    "            img_patches = img_patches.create_dataset('main',shape=(len(img_list),img_list[0].shape[0],img_list[0].shape[1]), dtype=int)\n",
    "        \n",
    "        # iterate over all images in the list\n",
    "        for i, img in tqdm(enumerate(img_list)):\n",
    "\n",
    "            # resize the images\n",
    "            if size is not None: \n",
    "                img = cv2.resize(img, (size[1],size[0]))\n",
    "\n",
    "            # add the resized image to the dataset\n",
    "            img_patches[i:i+1,:,:] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockshaped(arr, height, width, pad=False):\n",
    "    \"\"\"\n",
    "    Take a 2D matrix and returns a 3D matrix of image patches of format: [patch_nr, height, width].\n",
    "    The default is to crop the matrix. If pad is set to true arr is resized\n",
    "    to a multiple of height and width to be dividable with out rest.\n",
    "    \n",
    "    Args:\n",
    "        arr: The 2D matrix\n",
    "        height: The height for the patches\n",
    "        width: The height for the patches\n",
    "        pad: If true arr is resized to a multiple of height and width\n",
    "        \n",
    "    Return:\n",
    "        A 3D matrix of shape [patch_nr, height, width] with slide window order.\n",
    "    \"\"\"\n",
    "    # shape of the 2D matrix\n",
    "    h, w = arr.shape\n",
    "    \n",
    "    # assert that the patch size is smaller then the 2D matrix size\n",
    "    assert h >= height, f\"Image height {h} must be larger equal {height}\"\n",
    "    assert w >= width, f\"Image width {w} must be larger equal {width}\"\n",
    "\n",
    "    if not pad:\n",
    "        # crop the matrix to a size that is dividable with out rest \n",
    "        arr_resized = arr[:(height*int(h/height)), :(width*int(w/width))]\n",
    "        h, w = arr_resized.shape\n",
    "    else:\n",
    "        # apply zero padding to make the 2D matrix dividable with out rest \n",
    "        h_pad = (height - (h% height))\n",
    "        w_pad = (width - (w% width))\n",
    "        arr_resized = np.zeros((h+h_pad, w+w_pad))\n",
    "        arr_resized[:h, :w] = arr\n",
    "\n",
    "    # assert that the 2D matrix is dividable with out rest by height, width\n",
    "    assert h % height == 0, f\"{h} rows is not evenly divisible by {height}\"\n",
    "    assert w % width == 0, f\"{w} cols is not evenly divisible by {width}\"\n",
    "    \n",
    "    # slice the matrix in to the patches\n",
    "    return int(h/height), int(w/width), (arr_resized.reshape(h//height, height, -1, width)\n",
    "               .swapaxes(1,2)\n",
    "               .reshape(-1, height, width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    OKGREEN = '\\033[92m'\n",
    "    RED = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify which image patches to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m  \n",
      "\u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m  \n",
      "\u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m  \n",
      "\u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m \u001b[92m\u001b[1m.\u001b[0m\u001b[0m  \n"
     ]
    }
   ],
   "source": [
    "# retrive the shape of the upscalled images\n",
    "scaled_image_size = (cfg.IMG_SHAPE[0] * cfg.SCALE[0],cfg.IMG_SHAPE[1] * cfg.SCALE[1])\n",
    "\n",
    "# retrive the number of patches\n",
    "PATCH_NR_HEIGHT = int(scaled_image_size[0]//cfg.BLOCKSIZE[0])\n",
    "PATCH_NR_WIDTH = int(scaled_image_size[1]//cfg.BLOCKSIZE[1])\n",
    "\n",
    "# keep track of the patch numbers of the discarded and kept patchs\n",
    "discard_patches = []\n",
    "keep_patches = []\n",
    "\n",
    "# count how many patches are discarded, kept and the total of all patches\n",
    "count_keep = 0\n",
    "count_disc = 0\n",
    "count_total = 0\n",
    "\n",
    "# iterate over the image height\n",
    "for i in range(0, PATCH_NR_HEIGHT): \n",
    "    # iterate over the image width\n",
    "    for j in range(0, PATCH_NR_WIDTH):\n",
    "        count_total+=1\n",
    "        # discard the patch if it part of the outer top or bottom\n",
    "        if i < cfg.DISCARD_PATCH_TOP_BOT[0] or i > PATCH_NR_HEIGHT-cfg.DISCARD_PATCH_TOP_BOT[1]-1:\n",
    "            discard_patches.append(j+(i*PATCH_NR_WIDTH))\n",
    "            print(f\"{bcolors.RED}{bcolors.BOLD}.{bcolors.ENDC}{bcolors.ENDC}\", end=\" \")\n",
    "            count_disc +=1\n",
    "        # discard the patch if it part of the outer right or left\n",
    "        elif j < cfg.DISCARD_PATCH_LEFT_RIGHT[0] or j > PATCH_NR_WIDTH-cfg.DISCARD_PATCH_LEFT_RIGHT[1]-1:\n",
    "            discard_patches.append(j+(i*PATCH_NR_WIDTH))\n",
    "            print(f\"{bcolors.RED}{bcolors.BOLD}.{bcolors.ENDC}{bcolors.ENDC}\", end=\" \")\n",
    "            count_disc +=1\n",
    "        # keep the patch if it is part of the center\n",
    "        else:\n",
    "            keep_patches.append(j+(i*PATCH_NR_WIDTH))\n",
    "            print(f\"{bcolors.OKGREEN}{bcolors.BOLD}.{bcolors.ENDC}{bcolors.ENDC}\", end=\" \")\n",
    "            count_keep +=1\n",
    "    # add a new line\n",
    "    print(\" \")\n",
    "\n",
    "assert(PATCH_NR_HEIGHT*PATCH_NR_WIDTH==(count_keep+count_disc)), \"The sum of discarded and kept patches does not match the orginal number of patches\"\n",
    "assert((PATCH_NR_HEIGHT-cfg.DISCARD_PATCH_TOP_BOT[0]-cfg.DISCARD_PATCH_TOP_BOT[1])*(PATCH_NR_WIDTH-cfg.DISCARD_PATCH_LEFT_RIGHT[0]-cfg.DISCARD_PATCH_LEFT_RIGHT[1])==count_keep), \"Assert that the number of kept patches add up\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patch the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/submission_255_512_512/testA'\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "try:\n",
    "    os.makedirs(cfg.SAVEA, exist_ok=False)\n",
    "except FileExistsError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 45273.91it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 46419.17it/s]\n",
      "255it [00:34,  7.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# open the source files for reading\n",
    "with tifffile.TiffFile(cfg.TIFIMG) as img, \\\n",
    "     tifffile.TiffFile(cfg.H5SEGGT) as seg:\n",
    "        \n",
    "    \n",
    "    # retrive the information from the tiffi files including the image name tags\n",
    "    tif_tags = {}\n",
    "    for tag in tqdm(img.pages[0].tags.values()):\n",
    "        name, value = tag.name, tag.value\n",
    "        tif_tags[name] = value\n",
    "        \n",
    "    # retrive the information from the tiffi files including the image name tags\n",
    "    tif_tags = {}\n",
    "    for tag in tqdm(seg.pages[0].tags.values()):\n",
    "        name, value = tag.name, tag.value\n",
    "        tif_tags[name] = value\n",
    "        \n",
    "    # keep track of the images that have been saved    \n",
    "    saved_img = 0\n",
    "\n",
    "    # iterate over the images and their corresponding names\n",
    "    for i, (img, se) in tqdm(enumerate(zip(img.pages[:], seg.pages[:]))):\n",
    "        # only keep patches from the center slices \n",
    "\n",
    "        # convert tiffi image format to array\n",
    "        nr_patches_kept = 0\n",
    "        img = img.asarray()\n",
    "        se = se.asarray()\n",
    "\n",
    "        # 3. Slice the masked image and the GT seg. masks\n",
    "        _, _, seg_blocks = blockshaped(se, cfg.BLOCKSIZE[0], cfg.BLOCKSIZE[1])\n",
    "\n",
    "        rows, cols, img_blocks = blockshaped(img, cfg.BLOCKSIZE[0], cfg.BLOCKSIZE[1])\n",
    "\n",
    "        # 4. Save image patches and corresponding segmentation\n",
    "        for j in range(0,img_blocks.shape[0]):\n",
    "            # only save the previously identified center patches\n",
    "            if j in keep_patches:\n",
    "                nr_patches_kept +=1\n",
    "                Image.fromarray((img_blocks[j,:,:]).astype('uint8')).save(os.path.join(cfg.SAVEA,str(i)+'_block_'+str(j)+'.png'))\n",
    "                Image.fromarray((seg_blocks[j,:,:]).astype('uint8')).save(os.path.join(cfg.SAVEAGT,str(i)+'_block_'+str(j)+'.png'))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer the image patches to the ExM domain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------- Break -------\n",
    "\n",
    "Tranfer the image patches using a trained CylceGAN\n",
    "\n",
    "------- Break -------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the images\n",
    "\n",
    "To evaluate the previus steps and since I do not want to include the CycleGAN logic into this notebook we are merging the previus created EM source dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import image paths\n",
    "#! pip install natsort\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# load the image paths and sort them\n",
    "imgs = natsorted(glob(cfg.SAVEA+'/*'))\n",
    "\n",
    "##with tifffile.TiffFile('seg_temp.tif') as tif: \n",
    "##    stack = tif.asarray() # no need for `key` because pages in same series\n",
    "##    print(type(stack[0][0][0]))\n",
    "    \n",
    "# calculate the number of patches per slice\n",
    "nr_patches_height = PATCH_NR_HEIGHT-cfg.DISCARD_PATCH_TOP_BOT[0]-cfg.DISCARD_PATCH_TOP_BOT[1]\n",
    "nr_patches_width = PATCH_NR_WIDTH-cfg.DISCARD_PATCH_LEFT_RIGHT[0]-cfg.DISCARD_PATCH_LEFT_RIGHT[1]\n",
    "pp_slice = int((nr_patches_height) * (nr_patches_width))\n",
    "\n",
    "# keep track of the number of merged images\n",
    "count = 0\n",
    "\n",
    "# zero matrixes in which to store the image patches\n",
    "#merged_images = np.zeros((cfg.DISCARD_SLICE_TOP_BOT[1] - cfg.DISCARD_SLICE_TOP_BOT[0], nr_patches_height * cfg.BLOCKSIZE[0], nr_patches_width * cfg.BLOCKSIZE[1]))\n",
    "merged_images = np.zeros((126, nr_patches_height * cfg.BLOCKSIZE[0], nr_patches_width * cfg.BLOCKSIZE[1]))\n",
    "#merged_masks = np.zeros((cfg.DISCARD_SLICE_TOP_BOT[1] - cfg.DISCARD_SLICE_TOP_BOT[0], nr_patches_height * cfg.BLOCKSIZE[0], nr_patches_width * cfg.BLOCKSIZE[1]))\n",
    "#merged_masks = merged_masks.astype('uint32')\n",
    "\n",
    "assert(len(imgs)/pp_slice==merged_images.shape[0]), \"The number of patches and slices do not agree\"\n",
    "\n",
    "# iterate over the number of slices = number of patches / patches per slice\n",
    "for l in tqdm(range(0, int(len(imgs)/pp_slice))):\n",
    "    # iterate over the rows\n",
    "    for i in range(0, nr_patches_height):\n",
    "        # iterate over the columns - 1, as we concatenate the previous we the next slice in each iteration\n",
    "        for j in range(0,nr_patches_width):\n",
    "            #print(l,int(cfg.BLOCKSIZE[0]*i), int(cfg.BLOCKSIZE[0]*(i+1)),int(cfg.BLOCKSIZE[1]*j),int(cfg.BLOCKSIZE[1]*(j+1)))\n",
    "            merged_images[l,int(cfg.BLOCKSIZE[0]*i):int(cfg.BLOCKSIZE[0]*(i+1)),int(cfg.BLOCKSIZE[1]*j):int(cfg.BLOCKSIZE[1]*(j+1))] = Image.open(imgs[(i*(nr_patches_width))+j+pp_slice*l])\n",
    "            #merged_masks[l,int(cfg.BLOCKSIZE[0]*i):int(cfg.BLOCKSIZE[0]*(i+1)),int(cfg.BLOCKSIZE[1]*j):int(cfg.BLOCKSIZE[1]*(j+1))] = stack[(i*(nr_patches_width))+j+pp_slice*l, :, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.set_cmap(\"gray\")\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(merged_images[15])\n",
    "print(type(merged_images[0][0][0]))\n",
    "print(merged_images.shape)\n",
    "plt.savefig(\"em_dorsal_3D_full.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tifffile.TiffFile('seg_temp.tif') as tif, \\\n",
    "    stack = tif.asarray() \n",
    "    create_h5s(stack,'/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/dorsal_crop_volume_small/gt_seg_mask_uint32.h5', size=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the merged images to h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_h5s(np.asarray(merged_images).astype('uint8') ,\"/n/pfister_lab2/Lab/leander/em2exm/img_toolbox/em_img_dorsal_crop_volume_infer_dense.h5\", size=None)\n",
    "create_h5s(np.asarray(merged_masks).astype('uint32') ,\"/n/pfister_lab2/Lab/leander/em2exm/img_toolbox/em_seg_dorsal_crop_volume_infer_dense.h5\", size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the transfered ExM data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import image paths\n",
    "#! pip install natsort\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#with h5py.File(\"/n/pfister_lab2/Lab/leander/em2exm/slurm_jobs/ccgan__dorsal_crop_volume_infer__vanilla__20E_15DE/seg_em2exm_f0_img_patches.hdf5\", 'r') as images:\n",
    "with h5py.File(\"/n/pfister_lab2/Lab/leander/em2exm/slurm_jobs/ccgan__dorsal_crop_dense__vanilla__25E_20DE_transfer/seg_em2exm_f0_img_patches.hdf5\", 'r') as images:\n",
    "#with h5py.File(\"/n/pfister_lab2/Lab/leander/em2exm/slurm_jobs/ccgan__dorsal_crop_dense__vanilla__20E_15DE_transfer/seg_em2exm_f0_img_patches.hdf5\", 'r') as images:\n",
    "\n",
    "\n",
    "    imgs = images.get('main')\n",
    "    # calculate the number of patches per slice\n",
    "    nr_patches_height = PATCH_NR_HEIGHT-cfg.DISCARD_PATCH_TOP_BOT[0]-cfg.DISCARD_PATCH_TOP_BOT[1]\n",
    "    nr_patches_width = PATCH_NR_WIDTH-cfg.DISCARD_PATCH_LEFT_RIGHT[0]-cfg.DISCARD_PATCH_LEFT_RIGHT[1]\n",
    "    pp_slice = int((nr_patches_height) * (nr_patches_width))\n",
    "\n",
    "\n",
    "    # keep track of the number of merged images\n",
    "    count = 0\n",
    "\n",
    "    # zero matrixes in which to store the image patches\n",
    "    #merged_exm_images = np.zeros((cfg.DISCARD_SLICE_TOP_BOT[1] - cfg.DISCARD_SLICE_TOP_BOT[0], nr_patches_height * (cfg.BLOCKSIZE[0]*2), nr_patches_width * (cfg.BLOCKSIZE[1]*2)))\n",
    "    merged_exm_images = np.zeros((126, nr_patches_height * (cfg.BLOCKSIZE[0]), nr_patches_width * (cfg.BLOCKSIZE[1])))\n",
    "\n",
    "\n",
    "    assert(len(imgs)/pp_slice==merged_exm_images.shape[0]), \"The number of patches and slices do not agree\"\n",
    "\n",
    "    # iterate over the number of slices = number of patches / patches per slice\n",
    "    for l in tqdm(range(0, int(len(imgs)/pp_slice))):\n",
    "        # iterate over the rows\n",
    "        for i in range(0, nr_patches_height):\n",
    "            # iterate over the columns - 1, as we concatenate the previous we the next slice in each iteration\n",
    "            for j in range(0,nr_patches_width):\n",
    "                img = zoom(imgs[(i*(nr_patches_width))+j+pp_slice*l], (0.5,0.5), order=0)\n",
    "                merged_exm_images[l,int(cfg.BLOCKSIZE[0]*i):int(cfg.BLOCKSIZE[0]*(i+1)),int(cfg.BLOCKSIZE[1]*j):int(cfg.BLOCKSIZE[1]*(j+1))] = img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.set_cmap(\"gray\")\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(merged_exm_images[15])\n",
    "plt.savefig(\"exm_syn__ccgan__trained_dorsal_crop_dense__infer_dorsal_crop_3D_full__vanilla__25E_20DE_transfer.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_h5s(np.asarray(merged_exm_images).astype('uint8') ,\"/n/pfister_lab2/Lab/leander/em2exm/img_toolbox/exm_img_dorsal_ccgan__dorsal_crop_dense__vanilla__25E_20DE.h5\", size=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image manipulation\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# data format handling\n",
    "import tifffile\n",
    "import h5py\n",
    "\n",
    "# utility, visualization, and path handling \n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# system configurations handling\n",
    "from yacs.config import CfgNode as CN\n",
    "\n",
    "# 3D tensor handling\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import csv\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_C = CN()\n",
    "\n",
    "_C.EM_H5SEGGT = '/n/pfister_lab2/Lab/vcg_connectomics/EM/zebraFish/benchmark/seg_gt.h5'\n",
    "_C.EXM_H5IMGS = '/n/pfister_lab2/Lab/zudilin/data/Expansion/image/dorsal_6_histeq.h5'\n",
    "_C.ROOT = \"/n/pfister_lab2/Lab/leander/cerberus/neuro_glancer/data\"\n",
    "\n",
    "# using the segmentation instead of the images\n",
    "_C.EM_SEG = True\n",
    "\n",
    "_C.EM_SCALE = tuple((1, 3, 3))\n",
    "_C.EXM_SCALE = tuple((1, 0.25, 0.25))\n",
    "\n",
    "_C.EM_IMG_SHAPE = (1450, 2000)\n",
    "_C.EM_IMG_LEN = 397\n",
    "\n",
    "\n",
    "_C.EM_D_BOUND_0 = 100\n",
    "_C.EM_D_BOUND_1 = 305\n",
    "_C.EM_H_BOUND_0 = 639\n",
    "_C.EM_H_BOUND_1 = 810\n",
    "_C.EM_W_BOUND_0 = 914\n",
    "_C.EM_W_BOUND_1 = 1085\n",
    "\n",
    "_C.TARGET_SIZE = (255,512,512)\n",
    "\n",
    "def get_cfg_defaults():\n",
    "  \"\"\"Get a yacs CfgNode object with default values for my_project.\"\"\"\n",
    "  # Return a clone so that the defaults will not be altered\n",
    "  # This is for the \"local variable\" use pattern\n",
    "  return _C.clone()\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "#cfg.merge_from_file(\"./configs/base_setup.yaml\")\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_h5s(img_list, img_file_name, shape=None):\n",
    "    \"\"\" Take a list of images and writes them to a h5 file\n",
    "    \n",
    "        Args:\n",
    "            img_list: List of images that should be written to the h5-file\n",
    "            img_file_name: Name for the h5-file\n",
    "            shape: shape of the images\n",
    "    \"\"\"\n",
    "\n",
    "    # open a h5-file for writing\n",
    "    with h5py.File(img_file_name, \"w\") as img_patches:\n",
    "        \n",
    "        imgh5 = img_patches.create_dataset('main',shape=shape, dtype=int)\n",
    "    \n",
    "        # iterate over all images in the list\n",
    "        for i, img in tqdm(enumerate(img_list)):\n",
    "            # add the resized image to the dataset\n",
    "            imgh5[i:i+1,:,:] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patch the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/n/pfister_lab2/Lab/leander/cerberus/neuro_glancer/data'\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "try:\n",
    "    os.makedirs(cfg.ROOT, exist_ok=False)\n",
    "except FileExistsError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:00, 245.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 171, 171)\n",
      "(2, 3, 3)\n",
      "(255, 512, 512)\n",
      "(255, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "255it [00:01, 249.10it/s]\n",
      "255it [00:34,  7.37it/s]\n",
      "22it [00:00, 219.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/pfister_lab2/Lab/leander/cerberus/neuro_glancer/data/em_3D_2_3_3.h5\n",
      "/n/pfister_lab2/Lab/leander/cerberus/neuro_glancer/data/exm_3D_1_025_025.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "255it [00:00, 413.02it/s]\n",
      "255it [00:00, 379.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# open the source files for reading\n",
    "with h5py.File(cfg.EM_H5SEGGT) as EM, \\\n",
    "        h5py.File(cfg.EXM_H5IMGS) as ExM:\n",
    "        \n",
    "    \n",
    "    # retrive the GT segmentation\n",
    "    em = np.asarray(EM.get(list(EM.keys())[0]))[cfg.EM_D_BOUND_0:cfg.EM_D_BOUND_1,\n",
    "                                                cfg.EM_H_BOUND_0:cfg.EM_H_BOUND_1,\n",
    "                                                cfg.EM_W_BOUND_0:cfg.EM_W_BOUND_1]\n",
    "    # retrive the GT segmentation\n",
    "    exm = np.asarray(ExM.get(list(ExM.keys())[0]))\n",
    "    \n",
    "    print(em.shape)\n",
    "    print(cfg.EM_SCALE)\n",
    "    em_final = np.zeros(cfg.TARGET_SIZE)\n",
    "    exm_final = np.zeros(cfg.TARGET_SIZE)\n",
    "    print(em_final.shape)\n",
    "    print(exm_final.shape)\n",
    "    \n",
    "    for i, e in tqdm(enumerate(em)):      \n",
    "        if cfg.EM_SEG:\n",
    "            e = resize(e, cfg.TARGET_SIZE[1:], order=0, anti_aliasing=False, preserve_range=True)\n",
    "        else:\n",
    "            e = resize(e, cfg.TARGET_SIZE[1:], order=1, preserve_range=True, anti_aliasing=True)\n",
    "\n",
    "        assert(e.shape == em_final.shape[1:]), f\"the actual shape is {e.shape} \"\n",
    "\n",
    "        em_final[i, :, :] = e\n",
    "        \n",
    "    for i, e in tqdm(enumerate(exm)): \n",
    "        e = resize(e, cfg.TARGET_SIZE[1:], order=1, preserve_range=True, anti_aliasing=True)\n",
    "        \n",
    "\n",
    "        assert(e.shape == exm_final.shape[1:]), f\"the actual shape is {e.shape}\"\n",
    "\n",
    "        exm_final[i, :, :] = e\n",
    "\n",
    "\n",
    "\n",
    "    em_name = 'em_3D_'+'_'.join([ str(e) for e in cfg.EM_SCALE])+'.h5'\n",
    "    exm_name = 'exm_3D_1_025_025.h5'\n",
    "    em_path = os.path.join(cfg.ROOT, em_name)\n",
    "    exm_path = os.path.join(cfg.ROOT, exm_name)\n",
    "    \n",
    "    print(em_path)\n",
    "    print(exm_path)\n",
    "\n",
    "    create_h5s(exm_final, exm_path, exm_final.shape)\n",
    "    create_h5s(em_final, em_path, em_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 171, 171)\n",
      "(255, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "# open the source files for reading\n",
    "with h5py.File(cfg.EM_H5SEGGT) as EM, \\\n",
    "        h5py.File(cfg.EXM_H5IMGS) as ExM:\n",
    "        \n",
    "    \n",
    "    # retrive the GT segmentation\n",
    "    em = np.asarray(EM.get(list(EM.keys())[0]))[cfg.EM_D_BOUND_0:cfg.EM_D_BOUND_1,\n",
    "                                                cfg.EM_H_BOUND_0:cfg.EM_H_BOUND_1,\n",
    "                                                cfg.EM_W_BOUND_0:cfg.EM_W_BOUND_1]\n",
    "\n",
    "    # retrive the GT segmentation\n",
    "    exm = np.asarray(ExM.get(list(ExM.keys())[0]))\n",
    "    \n",
    "    \n",
    "    print(em.shape)\n",
    "    print(exm.shape)\n",
    "    \n",
    "    if cfg.EM_SEG:\n",
    "        em_zoom = zoom(em, cfg.EM_SCALE, order=0) #resize(e, cfg.TARGET_SIZE[1:], order=0, anti_aliasing=False, preserve_range=True)\n",
    "    else:\n",
    "        em_zoom  = zoom(em, cfg.EM_SCALE, order=1) #resize(e, cfg.TARGET_SIZE[1:], order=1, preserve_range=True, anti_aliasing=True)\n",
    "\n",
    "        assert(em_zoom .shape == tuple([ int(e*s) for e,s in zip(em.shape,cfg.EM_SCALE)])), f\"the actual shape is {em.shape}\"\n",
    "\n",
    "        \n",
    "    exm_zoom = zoom(exm, cfg.EM_SCALE, order=1) #resize(e, cfg.TARGET_SIZE[1:], order=1, preserve_range=True, anti_aliasing=True)\n",
    "        \n",
    "    assert(exm_zoom.shape == tuple([ int(e*s) for e,s in zip(exm.shape,cfg.EXM_SCALE)])), f\"the actual shape is {e.shape}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    em_name = 'em_3D_'+_.join(cfg.EM_SCALE)+'.h5'\n",
    "    exm_name = 'seg_3D_'+_.join(cfg.EXM_SCALE)+'.h5'\n",
    "    em_path = os.path.join(cfg.ROOT, em_name)\n",
    "    exm_path = os.path.join(cfg.ROOT, exm_name)\n",
    "    \n",
    "    print(em_path)\n",
    "    print(exm_path)\n",
    "\n",
    "    create_h5s(exm_zoom, exm_path, exm_final.shape)\n",
    "    create_h5s(em_zoom, em_path, em_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

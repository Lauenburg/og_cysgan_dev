{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tifffile\n",
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yacs in /n/home05/lauenburg/.conda/envs/img_toolbox/lib/python3.7/site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML in /n/home05/lauenburg/.conda/envs/img_toolbox/lib/python3.7/site-packages (from yacs) (6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install yacs\n",
    "from yacs.config import CfgNode as CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_C = CN()\n",
    "\n",
    "#_C.H5IMGS = '/n/pfister_lab2/Lab/zudilin/data/Expansion/image/dorsal_6_histeq.h5'\n",
    "#_C.H5IMGS = '/n/pfister_lab2/Lab/leander/cerberus/ccgan/datasets/dorsal_crop_3D_255_512/testB/exm_3D_255_512_512.tif'\n",
    "_C.H5IMGS = '/n/pfister_lab2/Lab/zudilin/data/NucExM/NucExM-Release/downsampled/image4_ds_4x.h5'\n",
    "\n",
    "\n",
    "#_C.SAVEB = '/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/dorsal_crop_volume/trainB/'#'../../cgan/pytorch-CycleGAN-and-pix2pix/datasets/em2exm/sub_dataset_round/testB/F000_Round1_c4_' \n",
    "#_C.SAVEB = '/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/submission_255_512_512/testB'#'../../cgan/pytorch-CycleGAN-and-pix2pix/datasets/em2exm/sub_dataset_round/testB/F000_Round1_c4_' \n",
    "#_C.SAVEB = '/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/submission_vol4_255_512/trainB/'\n",
    "_C.SAVEB = '/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/submission_vol4_255_512/testB/'\n",
    "\n",
    "_C.BLOCKSIZE = [128,128]#[2048,2048]\n",
    "#_C.SCALE = [0.25,0.25] #[1/16,1/16] \n",
    "_C.SCALE = [1,1]\n",
    "\n",
    "_C.NRSAVEIMG = float(\"inf\") # number of image blocks that should be saved\n",
    "\n",
    "_C.FILTER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cfg_defaults():\n",
    "  \"\"\"Get a yacs CfgNode object with default values for my_project.\"\"\"\n",
    "  # Return a clone so that the defaults will not be altered\n",
    "  # This is for the \"local variable\" use pattern\n",
    "  return _C.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg_defaults()\n",
    "#cfg.merge_from_file(\"./configs/base_setup.yaml\")\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockshaped(arr, height, width, pad=False):\n",
    "    \"\"\"\n",
    "    Resizes the 2D matrix arr to a mutlipte of height and width to be devidable with out rest.\n",
    "    The default is to crop the matrix. If pad is set to true the matrix is extended with zeros.\n",
    "    \"\"\"\n",
    "    h, w = arr.shape\n",
    "    \n",
    "    assert h >= height, f\"Image height {h} must be larger equal {height}\"\n",
    "    assert w >= width, f\"Image width {w} must be larger equal {width}\"\n",
    "\n",
    "    if not pad:\n",
    "        arr_resized = arr[:(height*int(h/height)), :(width*int(w/width))]\n",
    "        h, w = arr_resized.shape\n",
    "    else:\n",
    "        h_pad = (height - (h% height))\n",
    "        w_pad = (width - (w% width))\n",
    "        arr_resized = np.zeros((h+h_pad, w+w_pad))\n",
    "        arr_resized[:h, :w] = arr\n",
    "\n",
    "    assert h % height == 0, f\"{h} rows is not evenly divisible by {height}\"\n",
    "    assert w % width == 0, f\"{w} cols is not evenly divisible by {width}\"\n",
    "    return int(h/height), int(w/width), (arr_resized.reshape(h//height, height, -1, width)\n",
    "               .swapaxes(1,2)\n",
    "               .reshape(-1, height, width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_h5s(img_list, img_file_name, size=None):\n",
    "    \"\"\" Take a list of images and writes them to a h5 file\n",
    "    \n",
    "        Args:\n",
    "            img_list: List of images that should be written to the h5-file\n",
    "            img_file_name: Name for the h5-file\n",
    "            size: Size to which the images are resized, has to be an int tuple\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # open a h5-file for writing\n",
    "    with h5py.File(img_file_name, \"w\") as img_patches:\n",
    "        \n",
    "        # create the dataset specifing key and shape of the dataset\n",
    "        if size is not None:\n",
    "            assert isinstance(size, tuple)\n",
    "            img_patches = img_patches.create_dataset('main',shape=(len(img_list),size[0],size[1]), dtype=int)\n",
    "        else:\n",
    "            img_patches = img_patches.create_dataset('main',shape=(len(img_list),img_list[0].shape[0],img_list[0].shape[1]), dtype=int)\n",
    "        \n",
    "        # iterate over all images in the list\n",
    "        for i, img in tqdm(enumerate(img_list)):\n",
    "\n",
    "            # resize the images\n",
    "            if size is not None: \n",
    "                img = cv2.resize(img, (size[1],size[0]))\n",
    "\n",
    "            # add the resized image to the dataset\n",
    "            img_patches[i:i+1,:,:] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting sub-volume from dorsal 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 13.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX:  255\n",
      "MIN:  0\n",
      "STD:  44.01981026689214\n",
      "MEAN:  78.76063437368356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "255it [00:22, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 4080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "UPSAMPLE = cfg.SCALE\n",
    "BLOCK_SIZE = cfg.BLOCKSIZE\n",
    "\n",
    "#with h5py.File(cfg.H5IMGS) as hdf_dorsal:\n",
    "with tifffile.TiffFile(cfg.H5IMGS) as hdf_dorsal:\n",
    "    \n",
    "    # get the masks\n",
    "    #hdf_dorsal_keys = list(hdf_dorsal.keys()) # prints ['main']\n",
    "    #hdf_dors = hdf_dorsal.get(hdf_dorsal_keys[0])\n",
    "    hdf_dors = np.asarray([e.asarray() for e in hdf_dorsal.pages[:]])\n",
    "    print(hdf_dors[0].shape)\n",
    "    \n",
    "    IMG_SIZE_H = hdf_dors[0,:,:].shape[0] *  UPSAMPLE[0]\n",
    "    IMG_SIZE_W = hdf_dors[0,:,:].shape[1] *  UPSAMPLE[1]\n",
    "    \n",
    "    IMG_SIZE_H = hdf_dors[0,:,:].shape[0] * UPSAMPLE[0]\n",
    "    IMG_SIZE_W = hdf_dors[0,:,:].shape[1] * UPSAMPLE[1]\n",
    "\n",
    "    max_pixel = np.array(hdf_dors).max()\n",
    "    min_pixel = np.array(hdf_dors).min()\n",
    "    std = np.array(hdf_dors).std()\n",
    "    mean = np.mean(np.array(hdf_dors))\n",
    "    \n",
    "    print(\"MAX: \", max_pixel)\n",
    "    print(\"MIN: \", min_pixel)\n",
    "        \n",
    "    print(\"STD: \", std)\n",
    "    print(\"MEAN: \", mean)\n",
    "\n",
    "    c_img = 0\n",
    "    c_patch =0\n",
    "    \n",
    "    # loop over all images in a dataset\n",
    "    for i, h in tqdm(enumerate(hdf_dors)):\n",
    "\n",
    "        # normalize based on max and min of current dataset\n",
    "        h = (h-min_pixel)/(max_pixel-min_pixel)\n",
    "        # resize the image\n",
    "        h = resize(h, (IMG_SIZE_H, IMG_SIZE_W))\n",
    "\n",
    "        # mean of current image\n",
    "        h_mean = np.mean(h)\n",
    "\n",
    "        # cut in to blocks\n",
    "        rows, cols, img_blocks = blockshaped(h,BLOCK_SIZE[0],BLOCK_SIZE[1])\n",
    "\n",
    "        # loop over the blocks\n",
    "        for j in range (0, img_blocks.shape[0]): \n",
    "            # only save those blocks whose mean are above the mean of the whole image\n",
    "            if not cfg.FILTER:\n",
    "                # save the image block\n",
    "                Image.fromarray((img_blocks[j,:,:] * 255).astype('uint8'), mode='L').save(os.path.join(cfg.SAVEB,str(i)+'_block_'+str(j)+'.png'))                \n",
    "                c_patch +=1\n",
    "                if c_patch == cfg.NRSAVEIMG:\n",
    "                    break\n",
    "            if cfg.FILTER and np.mean(img_blocks[j,:,:]) >= h_mean:\n",
    "                # save the image block\n",
    "                Image.fromarray((img_blocks[j,:,:] * 255).astype('uint8'), mode='L').save(os.path.join(cfg.SAVEB,str(i)+'_block_'+str(j)+'.png'))                \n",
    "                c_patch +=1\n",
    "                if c_patch == cfg.NRSAVEIMG:\n",
    "                    break\n",
    "        if c_patch == cfg.NRSAVEIMG:\n",
    "            break\n",
    "        c_img +=1\n",
    "\n",
    "print(c_img,c_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for specific slices and patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for sclices\n",
    "def filter_for_slice_range(slice_range):\n",
    "    def filter_slice(name):\n",
    "        for nr in slice_range:\n",
    "            if int(name.split('/')[-1].split('_')[0]) == nr:\n",
    "                return True\n",
    "        return False\n",
    "    return filter_slice\n",
    "\n",
    "# filter for block\n",
    "def filter_for_block_set(block_set):\n",
    "    def filter_block(name):\n",
    "        for nr in block_set:\n",
    "            if int(name.split('/')[-1].split('_')[-1].split('.')[0]) == nr:\n",
    "                return True\n",
    "        return False\n",
    "    return filter_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'testB'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7260/2236179808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mslice_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m175\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilter_sl_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_for_slice_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiltered_blocks_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_sl_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mblock_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfilter_bl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_for_block_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7260/3623690725.py\u001b[0m in \u001b[0;36mfilter_slice\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslice_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'testB'"
     ]
    }
   ],
   "source": [
    "blocks = glob.glob(cfg.SAVEB+'*')\n",
    "slice_range = list(range(75,175))\n",
    "filter_sl_range = filter_for_slice_range(slice_range)\n",
    "filtered_blocks_range = list(filter(filter_sl_range, blocks))\n",
    "block_set = [5,6,9,10]\n",
    "filter_bl = filter_for_block_set(block_set)\n",
    "filtered_block_set = list(filter(filter_bl, filtered_blocks_range))\n",
    "print(len(filtered_block_set))\n",
    "print(filtered_block_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the selected slices to the trainB folder\n",
    "for img in filtered_block_set:\n",
    "    copyfile(img, os.path.join('/n/pfister_lab2/Lab/leander/cgan/pytorch-CycleGAN-and-pix2pix/results/256_not_filtered_dorsal_crop/trainB', img.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exspects 2x2 image patches per slice\n",
    "from skimage.transform import resize\n",
    "\n",
    "with h5py.File('/n/pfister_lab2/Lab/leander/em2exm/pytorch_connectomics/datasets/inference/merged_256_not_filtered_dorsal_b.h5') as images:    \n",
    "    imgs = images.get('main')\n",
    "    sclice_count = [i*4 for i in range(0,100)]\n",
    "    merged_img_patches = []\n",
    "    for i in sclice_count[:]:\n",
    "        # Merge image patches\n",
    "        patches_top = np.concatenate((imgs[i],imgs[i+1]),axis=1)\n",
    "        patches_bot = np.concatenate((imgs[i+2],imgs[i+3]),axis=1)\n",
    "        merged_img_patches.append(np.concatenate((patches_top,patches_bot),axis=0))\n",
    "\n",
    "#plt.imshow(patch_work)\n",
    "merged_img_patches = np.asarray(merged_img_patches)\n",
    "print(merged_img_patches.shape)\n",
    "\n",
    "\n",
    "create_h5s(merged_seg_patches,\"./dense_seg_20E_15DE_3SW_SH_merged_248.h5\", size=(256,256))\n",
    "create_h5s(merged_img_patches,\"./dense_img_20E_15DE_3SW_SH_merged_248.h5\", size=(256,256))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

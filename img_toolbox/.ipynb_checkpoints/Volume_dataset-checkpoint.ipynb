{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from typing import Optional, List\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import tifffile\n",
    "#from data.base_dataset import BaseDataset\n",
    "import torchio as tio\n",
    "import sys\n",
    "\n",
    "# save the locations for joining the sub-volumes\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigException(Exception):\n",
    "    def __call__(self, *args):\n",
    "        return self.__class__(*(self.args + args))\n",
    "    def __str__(self):\n",
    "        return ': '.join(self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from typing import Optional, List\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import tifffile\n",
    "import torchio as tio\n",
    "from connectomics.data.augmentation import Compose\n",
    "from connectomics.data.augmentation import *\n",
    "\n",
    "# save the locations for joining the sub-volumes\n",
    "import csv\n",
    "\n",
    "from connectomics.data.utils import *\n",
    "\n",
    "#AUGMENTOR_TYPE = Optional[Compose]\n",
    "\n",
    "\n",
    "class CerberusDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for volumetric image datasets. At training time, subvolumes are randomly sampled from all the large \n",
    "    input volumes with (optional) rejection sampling to increase the frequency of foreground regions in a batch. At inference \n",
    "    time, subvolumes are yielded in a sliding-window manner with overlap to counter border artifacts. \n",
    "\n",
    "    Args:\n",
    "        volume (list): list of image volumes.\n",
    "        label (list, optional): list of label volumes. Default: None\n",
    "        sample_volume_size (tuple, int): model input size.\n",
    "        sample_label_size (tuple, int): model output size.\n",
    "        sample_stride (tuple, int): stride size for sampling.\n",
    "        mode (str): ``'train'`` or ``'test'``. Default: ``'train'``\n",
    "        target_opt (list): list the model targets generated from segmentation labels.\n",
    "        iter_num (int): total number of training iterations (-1 for inference). Default: -1\n",
    "        reject_size_thres (int, optional): threshold to decide if a sampled volumes contains foreground objects. Default: 0\n",
    "        reject_diversity (int, optional): threshold to decide if a sampled volumes contains multiple objects. Default: 0\n",
    "        reject_p (float, optional): probability of rejecting non-foreground volumes. Default: 0.95\n",
    "\n",
    "    Note: \n",
    "        For relatively small volumes, the total number of possible subvolumes can be smaller than the total number \n",
    "        of samples required in training (the product of total iterations and mini-natch size), which raises *StopIteration*. \n",
    "        Therefore the dataset length is also decided by the training settings.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def modify_commandline_options(parser, is_train):\n",
    "        \"\"\"Adding dataset-specific options.\n",
    "\n",
    "        Parameters:\n",
    "            parser          -- original option parser\n",
    "            is_train (bool) -- whether training phase or test phase. \n",
    "\n",
    "        Returns:\n",
    "            the modified parser.\n",
    "        \"\"\"\n",
    "        parser.add_argument('--tif_A_file_name', type=str, required=True, help='name of the tiff file for the data of domain A')\n",
    "        parser.add_argument('--tif_A_file_name_label', type=str, required=True, help='name of the tiff label file for the data of domain A')\n",
    "        parser.add_argument('--tif_B_file_name', type=str, required=True, help='name of the tiff file for the data of domain B')\n",
    "\n",
    "        parser.set_defaults(max_dataset_size=1000, new_dataset_option=2.0)  # specify dataset-specific default values\n",
    "        return parser\n",
    "\n",
    "    def __init__(self, opt=None):\n",
    "        \"\"\"Initialize this dataset class.\n",
    "\n",
    "        Parameters:\n",
    "            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n",
    "        \"\"\"\n",
    "        # save the option and dataset root\n",
    "        Dataset.__init__(self)\n",
    "        \n",
    "        self.opt = opt # experiment options\n",
    "        self.sample_volume_size = (17, 123, 123)\n",
    "        #self.sample_label_size = (opt.vs_z, opt.vs_x, opt.vs_y)\n",
    "        self.sample_label_size = (17, 97, 97)\n",
    "        #self.sample_stride = (opt.ss_z,opt.ss_x,opt.ss_y) # stride size\n",
    "        self.sample_stride = (1,1,1) # stride size\n",
    "        self.mode = 'train'\n",
    "\n",
    "        assert self.mode in ['train', 'test']\n",
    "        \n",
    "        kwargs = {'additional_targets': {'label'}}\n",
    "        self.augmentor = Compose(input_size=(17, 97, 97), transforms= [Rotate(p=1.0, **kwargs)])\n",
    "        self.augmentor.set_sample_params()\n",
    "\n",
    "        # setting contour dilation to two since contours of thickness one are to thin for the L1 loss \n",
    "        self.target_opt = ['0','4-1-1', '6'] # option for the label output: binary mask | binary mask + contours | ...\n",
    "        self.erosion_rates = None # erosion rate for the binary masks\n",
    "        self.dilation_rates = None # dilation rate for the binary masks\n",
    "        self.iter_num = -1 # total number of training iterations (-1 for inference)\n",
    "\n",
    "\n",
    "        # the image data should be of type uint8 \n",
    "        # labels should be of type uint8, uint16, uint32, or uint64 depending on the number of objects in the data\n",
    "        with tifffile.TiffFile('/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/dorsal_crop_3D_full/trainA/full_volume_em_3D_droped_85_75_80.tif') as tif_A, \\\n",
    "             tifffile.TiffFile('/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/dorsal_crop_3D_full/gt_seg_mask/full_volume_seg_3D_droped_85_75_80.tif') as tif_A_label, \\\n",
    "             tifffile.TiffFile('/n/pfister_lab2/Lab/leander/em2exm/ccgan/datasets/dorsal_crop_3D_full/trainB/full_volume_em_3D_droped0_0_0_tile_size_17_65_65.tif') as tif_B: \n",
    "\n",
    "                # convert to array\n",
    "                # no need for `key` because all pages are in same series \n",
    "                volume_A = tif_A.asarray()\n",
    "                volume_B = tif_B.asarray()\n",
    "                label = tif_A_label.asarray()\n",
    "\n",
    "                # assert data formats\n",
    "                assert(volume_A.dtype == \"uint8\"), \"The input image volume should be of type uint8\"\n",
    "                assert(volume_B.dtype == \"uint8\"), \"The input image volume should be of type uint8\"\n",
    "                assert(label.dtype in [\"uint8\" ,\"uint16\", \"uint32\", \"uint64\"]), \"The input label volume should be of type uint8 | uint16 | uint32 | uint64\"\n",
    "\n",
    "                # volume dataset can handle lists of different volumes\n",
    "                self.volume_A = [volume_A] \n",
    "                self.volume_B = [volume_B]\n",
    "                self.label = [label]\n",
    "\n",
    "        # print out the volume shapes\n",
    "        print(\"self.volume_A.shape \", np.asarray(self.volume_A).shape)\n",
    "        print(\"self.label.shape \", np.asarray(self.label).shape)\n",
    "        print(\"self.volume_B.shape \", np.asarray(self.volume_B).shape)\n",
    "\n",
    "        # dataset: channels, depths, rows, cols\n",
    "        # volume size, could be multi-volume input\n",
    "        self.volume_size_A = [np.array(x.shape) for x in self.volume_A]\n",
    "        self.volume_size_B = [np.array(x.shape) for x in self.volume_B]\n",
    "        \n",
    "\n",
    "        # convert the image sub-volume size to a numpy array\n",
    "        self.sample_volume_size = np.array(\n",
    "            self.sample_volume_size).astype(int)  \n",
    "\n",
    "        # convert the label sub-volume size to a numpy array\n",
    "        # calculate the scaling difference bet\n",
    "        if self.label is not None:\n",
    "            self.sample_label_size = np.array(\n",
    "                self.sample_label_size).astype(int)  # model label size\n",
    "            self.label_vol_ratio = self.sample_label_size / self.sample_volume_size\n",
    "            if self.augmentor is not None:\n",
    "                assert np.array_equal(\n",
    "                    self.augmentor.sample_size, self.sample_label_size)\n",
    "           \n",
    "        # assert the subvolume sizes are not larger then the volume sizes\n",
    "        self._assert_valid_shape()\n",
    "\n",
    "        # convert the stride size / stride size to a numpy array\n",
    "        self.sample_stride = np.array(self.sample_stride).astype(int)\n",
    "        \n",
    "        # compute number of samples for each dataset (multi-volume input)\n",
    "        # based on the possible positions of a sliding window of shape 'sample_volume_size' for a stride of 'sample_stride'\n",
    "        # similar to the positions of a convolution kernel\n",
    "        self.sample_size_A = [count_volume(self.volume_size_A[x], self.sample_volume_size, self.sample_stride)\n",
    "                            for x in range(len(self.volume_size_A))]\n",
    "        self.sample_size_B = [count_volume(self.volume_size_B[x], self.sample_volume_size, self.sample_stride)\n",
    "                            for x in range(len(self.volume_size_B))]\n",
    "\n",
    "        # total number of possible inputs for each volume\n",
    "        # sample_size_* is a 3D tuple holding the number of possible postions in the x,y,z direction\n",
    "        # the number of all possible postions is x*y*z\n",
    "        self.sample_num_A = np.array([np.prod(x) for x in self.sample_size_A])\n",
    "        self.sample_num_B = np.array([np.prod(x) for x in self.sample_size_B])\n",
    "        \n",
    "        # if we have multiple volumes the number of possible sub-volumes is the sum \n",
    "        # of possible sub-volumes of the singel volumes\n",
    "        self.sample_num_a_A = np.sum(self.sample_num_A)\n",
    "        self.sample_num_a_B = np.sum(self.sample_num_B)\n",
    "\n",
    "        # number of possible subvolumes = [0, #vol1, #vol1+#vol2, #vol1+#vol2+#vol1, ...]\n",
    "        self.sample_num_c_A = np.cumsum([0] + list(self.sample_num_A))\n",
    "        self.sample_num_c_B = np.cumsum([0] + list(self.sample_num_B))\n",
    "\n",
    "        # for validation and test -> [y*x, x]\n",
    "        # used the calculate the postion of a sample and not to run out of the image\n",
    "        if self.mode in ['test']: \n",
    "            self.sample_size_test_A = [\n",
    "                np.array([np.prod(x[1:3]), x[2]]) for x in self.sample_size_A]\n",
    "            self.sample_size_test_B = [\n",
    "                np.array([np.prod(x[1:3]), x[2]]) for x in self.sample_size_B]\n",
    "\n",
    "        # For relatively small volumes, the total number of samples can be generated is smaller\n",
    "        # than the number of samples required for training (i.e., iteration * batch size). Thus\n",
    "        # we let the __len__() of the dataset return the larger value among the two during training.\n",
    "        self.iter_num_A = max(\n",
    "            self.iter_num, self.sample_num_a_A) if self.mode == 'train' else self.sample_num_a_A\n",
    "        self.iter_num_B = max(\n",
    "            self.iter_num, self.sample_num_a_B) if self.mode == 'train' else self.sample_num_a_B\n",
    "        print('Total number of samples to be generated for A: ', self.iter_num_A)\n",
    "        print('Total number of samples to be generated for B: ', self.iter_num_B)\n",
    "\n",
    "    def __len__(self):\n",
    "        # total number of possible samples\n",
    "        return max(self.iter_num_A, self.iter_num_B)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # orig input: keep uint/int format to save cpu memory\n",
    "        # output sample: need np.float32\n",
    "\n",
    "        vol_size = self.sample_volume_size\n",
    "        if self.mode == 'train':\n",
    "\n",
    "            # random sample the sub-volume A\n",
    "            pos_A, out_volume_A, out_label = self._random_sampling(vol_size, \"A\")\n",
    "            \n",
    "            data = {'image': out_volume_A,\n",
    "                    'label': out_label,\n",
    "                    'valid_mask': None}\n",
    "\n",
    "            augmented = self.augmentor(data)\n",
    "            out_volume_A, out_label = augmented['image'], augmented['label']\n",
    "            \n",
    "            # normalize the image sub-volume to -1 to 1 and convert to float32 \n",
    "            out_volume_A = self._normalize(out_volume_A)\n",
    "            \n",
    "            # retrive the binary masks and the contour masks from the label\n",
    "            label = seg_to_targets(out_label, self.target_opt, self.erosion_rates, self.dilation_rates)\n",
    "            label = np.squeeze(np.asarray(label))\n",
    "\n",
    "            # random sample the sub-volume A - we only have labels for A\n",
    "            pos_B, out_volume_B, _  = self._random_sampling(vol_size, \"B\")\n",
    "            out_volume_B = self._normalize(out_volume_B)\n",
    "\n",
    "            # assert normalizations\n",
    "            assert(np.min(out_volume_A) >= -1.0 and np.max(out_volume_A) <= 1.0), \"The image sub-volumes have to be normalized between -1.0 and 1.0\"\n",
    "            assert(np.min(out_volume_B) >= -1.0 and np.max(out_volume_B) <= 1.0), \"The image sub-volumes have to be normalized between -1.0 and 1.0\"\n",
    "            # the binary mask and contour mask should normalized to a range of 0 to 1 while the distance map should be between -1 to 1 \n",
    "            if len(self.target_opt) == 2:\n",
    "                assert(np.min(label) >= 0.0 and np.max(label) <= 1.0), f\"The binary and contour mask have to be normalized between 0.0 and 1.0 and not {np.min(label)} and{np.max(label)}\"\n",
    "            elif len(self.target_opt) == 3:\n",
    "                assert(np.min(label[:2,:,:,:]) >= 0.0 and np.max(label[:2,:,:,:]) <= 1.0), f\"The binary and contour mask have to be normalized between 0.0 and 1.0 and not {np.min(label)} and{np.max(label)}\"\n",
    "                assert(np.min(label[2:3,:,:,:]) >= -1.0 and np.max(label[2:3,:,:,:]) <= 1.0), f\"The binary and contour mask have to be normalized between 0.0 and 1.0 and not {np.min(label)} and{np.max(label)}\"\n",
    "             \n",
    "            # assert data formats\n",
    "            assert(out_volume_A.dtype == \"float32\"), \"The input to a PyTorch network should always be of type float32\"\n",
    "            assert(out_volume_B.dtype  == \"float32\"), \"The input to a PyTorch network should always be of type float32\"\n",
    "            assert(label.dtype == \"float32\"), \"The input to a PyTorch network should always be of type float32\"\n",
    "\n",
    "            # convert the image sub-volume to tensor and add a batch dimension\n",
    "            out_volume_A = torch.Tensor(out_volume_A).reshape((1,out_volume_A.shape[0],out_volume_A.shape[1],out_volume_A.shape[2]))\n",
    "            out_volume_B = torch.Tensor(out_volume_B).reshape((1,out_volume_B.shape[0],out_volume_B.shape[1],out_volume_B.shape[2]))\n",
    "            label = torch.Tensor(label)\n",
    "\n",
    "            return {'A': out_volume_A, 'B': out_volume_B, 'Label': label, 'A_pos': pos_A, 'B_pos': pos_B, 'A_paths': \"z_\"+str(pos_A[1])+\"-\"+str(pos_A[1]+vol_size[0]) +\"_x_\"+ str(pos_A[2])+\"-\"+str(pos_A[2]+vol_size[1]) +\"_y_\"+ str(pos_A[3])+\"-\"+str(pos_A[3]+vol_size[2]), 'B_paths': \"z_\"+str(pos_B[1])+\"-\"+str(pos_B[1]+vol_size[0]) +\"_x_\"+ str(pos_B[2])+\"-\"+str(pos_B[2]+vol_size[1]) +\"_y_\"+ str(pos_B[3])+\"-\"+str(pos_B[3]+vol_size[2])}\n",
    "\n",
    "        elif self.mode == 'test':\n",
    "            pos_A = self._get_pos_test(index, \"A\")\n",
    "            pos_B = self._get_pos_test(index, \"B\")\n",
    "\n",
    "            # sub-volume A\n",
    "            out_volume_A = crop_volume(\n",
    "                self.volume_A[pos_A[0]], vol_size, pos_A[1:])\n",
    "            \n",
    "            #normalize sub-volume A\n",
    "            out_volume_A = self._normalize(out_volume_A)\n",
    "\n",
    "            # sub-volume B\n",
    "            out_volume_B = crop_volume(\n",
    "                self.volume_B[pos_B[0]], vol_size, pos_B[1:])\n",
    "\n",
    "            # normalize sub-volume B\n",
    "            out_volume_B = self._normalize(out_volume_B)\n",
    "\n",
    "            # label\n",
    "            out_label = crop_volume(self.label[pos_A[0]], vol_size, pos_A[1:])\n",
    "\n",
    "            # retrive the binary masks and the contour masks from the label\n",
    "            label = seg_to_targets(out_label, self.target_opt, self.erosion_rates, self.dilation_rates)\n",
    "            label = np.squeeze(np.asarray(label))\n",
    "\n",
    "            # convert the image sub-volume to tensor and add a batch dimension\n",
    "            assert(np.min(out_volume_A) >= -1.0 and np.max(out_volume_A) <= 1.0), \"The image sub-volumes have to be normalized between -1.0 and 1.0\"\n",
    "            assert(np.min(out_volume_B) >= -1.0 and np.max(out_volume_B) <= 1.0), f\"The image sub-volumes have to be normalized {np.min(label)} and{np.max(label)}\"\n",
    "\n",
    "            # the binary mask and contour mask should normalized to a range of 0 to 1 while the distance map should be between -1 to 1 \n",
    "            if len(self.target_opt) == 2:\n",
    "                assert(np.min(label) >= 0.0 and np.max(label) <= 1.0), f\"The binary and contour mask have to be normalized between 0.0 and 1.0 and not {np.min(label)} and{np.max(label)}\"\n",
    "            elif len(self.target_opt) == 3:\n",
    "                assert(np.min(label[:2,:,:,:]) >= 0.0 and np.max(label[:2,:,:,:]) <= 1.0), f\"The binary and contour mask have to be normalized between 0.0 and 1.0 and not {np.min(label)} and{np.max(label)}\"\n",
    "                assert(np.min(label[2:3,:,:,:]) >= -1.0 and np.max(label[2:3,:,:,:]) <= 1.0), f\"The binary and contour mask have to be normalized between 0.0 and 1.0 and not {np.min(label)} and{np.max(label)}\"\n",
    "                \n",
    "            # assert data formats\n",
    "            assert(out_volume_A.dtype == \"float32\"), \"The input to a PyTorch network should always be of type float32\"\n",
    "            assert(label.dtype == \"float32\"), \"The input to a PyTorch network should always be of type float32\"\n",
    "            assert(out_volume_B.dtype  == \"float32\"), \"The input to a PyTorch network should always be of type float32\"\n",
    "\n",
    "            # add batch dimension and convert to tensor\n",
    "            out_volume_A = torch.Tensor(out_volume_A).reshape((1,out_volume_A.shape[0],out_volume_A.shape[1],out_volume_A.shape[2]))\n",
    "            out_volume_B = torch.Tensor(out_volume_B).reshape((1,out_volume_B.shape[0],out_volume_B.shape[1],out_volume_B.shape[2]))\n",
    "            label = torch.Tensor(label)\n",
    "\n",
    "            return {'A': out_volume_A, 'B':  out_volume_B, 'Label': label, 'A_pos': pos_A, 'B_pos': pos_B, 'A_paths': \"z_\"+str(pos_A[1])+\"-\"+str(pos_A[1]+vol_size[0]) +\"_x_\"+ str(pos_A[2])+\"-\"+str(pos_A[2]+vol_size[1]) +\"_y_\"+ str(pos_A[3])+\"-\"+str(pos_A[3]+vol_size[2]), 'B_paths': \"z_\"+str(pos_B[1])+\"-\"+str(pos_B[1]+vol_size[0]) +\"_x_\"+ str(pos_B[2])+\"-\"+str(pos_B[2]+vol_size[1]) +\"_y_\"+ str(pos_B[3])+\"-\"+str(pos_B[3]+vol_size[2])}\n",
    "\n",
    "    #######################################################\n",
    "    # Position Calculator\n",
    "    #######################################################\n",
    "\n",
    "    def _index_to_dataset(self, index, AorB):\n",
    "        \"\"\"retrive the index of the dataset -> in case only a single volume was provided\n",
    "            the output will alsways be equal to zero\n",
    "        \"\"\"\n",
    "        if AorB == 'A':\n",
    "            return np.argmax(index < self.sample_num_c_A) - 1  # which dataset\n",
    "        elif AorB == 'B':\n",
    "            return np.argmax(index < self.sample_num_c_B) - 1  # which dataset\n",
    "\n",
    "    def _index_to_location(self, index, sz):\n",
    "        # index -> z,y,x\n",
    "        # sz: [y*x, x]\n",
    "        pos = [0, 0, 0]\n",
    "        pos[0] = np.floor(index/sz[0])\n",
    "        pz_r = index % sz[0]\n",
    "        pos[1] = int(np.floor(pz_r/sz[1]))\n",
    "        pos[2] = pz_r % sz[1]\n",
    "        return pos\n",
    "\n",
    "    def _get_pos_test(self, index, AorB):\n",
    "        \"Get the position of a sample based on the current index\"\n",
    "        pos = [0, 0, 0, 0]\n",
    "        did = self._index_to_dataset(index, AorB)\n",
    "        # set the dataset index -> allways zero in case of single volume\n",
    "        pos[0] = did\n",
    "\n",
    "        if AorB == 'A':\n",
    "            index2 = index - self.sample_num_c_A[did]\n",
    "            pos[1:] = self._index_to_location(index2, self.sample_size_test_A[did])\n",
    "            # if out-of-bound, tuck in\n",
    "            for i in range(1, 4):\n",
    "                if pos[i] != self.sample_size_A[pos[0]][i-1]-1:\n",
    "                    pos[i] = int(pos[i] * self.sample_stride[i-1])\n",
    "                else:\n",
    "                    pos[i] = int(self.volume_size_A[pos[0]][i-1] -\n",
    "                                self.sample_volume_size[i-1])\n",
    "        elif AorB == 'B':\n",
    "            index2 = index - self.sample_num_c_B[did]\n",
    "            pos[1:] = self._index_to_location(index2, self.sample_size_test_B[did])\n",
    "            # if out-of-bound, tuck in\n",
    "            for i in range(1, 4):\n",
    "                if pos[i] != self.sample_size_B[pos[0]][i-1]-1:\n",
    "                    pos[i] = int(pos[i] * self.sample_stride[i-1])\n",
    "                else:\n",
    "                    pos[i] = int(self.volume_size_B[pos[0]][i-1] -\n",
    "                                self.sample_volume_size[i-1])\n",
    "\n",
    "        return pos\n",
    "\n",
    "    def _get_pos_train(self, vol_size, AorB):\n",
    "        \"\"\"Retrives the position of a random sample\"\"\"\n",
    "        # random: multithread\n",
    "        # np.random: same seed\n",
    "        pos = [0, 0, 0, 0]\n",
    "        # pick a dataset\n",
    "        if AorB == 'A':\n",
    "            did = self._index_to_dataset(random.randint(0, self.sample_num_a_A-1), AorB)\n",
    "            pos[0] = did\n",
    "            # pick a position\n",
    "            tmp_size = count_volume(\n",
    "                self.volume_size_A[did], vol_size, self.sample_stride)\n",
    "            tmp_pos = [random.randint(0, tmp_size[x]-1) * self.sample_stride[x]\n",
    "                    for x in range(len(tmp_size))]\n",
    "        elif AorB == 'B':\n",
    "            did = self._index_to_dataset(random.randint(0, self.sample_num_a_B-1), AorB)\n",
    "            pos[0] = did\n",
    "            # pick a position\n",
    "            tmp_size = count_volume(\n",
    "                self.volume_size_B[did], vol_size, self.sample_stride)\n",
    "            tmp_pos = [random.randint(0, tmp_size[x]-1) * self.sample_stride[x]\n",
    "                    for x in range(len(tmp_size))]\n",
    "        pos[1:] = tmp_pos\n",
    "        return pos\n",
    "\n",
    "    #######################################################\n",
    "    # Volume Sampler\n",
    "    #######################################################\n",
    "    def _random_sampling(self, vol_size, AorB):\n",
    "        \"\"\"Randomly sample a subvolume from all the volumes. \n",
    "        \"\"\"\n",
    "        pos = self._get_pos_train(vol_size, AorB) # retrive position of random sample\n",
    "        return self._crop_with_pos(pos, vol_size, AorB) # crop's out the sample based on the given position\n",
    "\n",
    "    def _crop_with_pos(self, pos, vol_size, AorB):\n",
    "        \"Cropes out the sub-volume at position 'pos' that expends by size 'vol_size'\"\n",
    "        out_label = None\n",
    "        if AorB == 'A':\n",
    "            out_volume = crop_volume(\n",
    "                self.volume_A[pos[0]], vol_size, pos[1:])\n",
    "                    # position in the label and valid mask\n",
    "            out_label = None\n",
    "            if self.label is not None:\n",
    "                pos_l = np.round(pos[1:]*self.label_vol_ratio)\n",
    "                out_label = crop_volume(\n",
    "                    self.label[pos[0]], self.sample_label_size, pos_l)\n",
    "                # For warping: cv2.remap requires input to be float32.\n",
    "                # Make labels index smaller. Otherwise uint32 and float32 are not\n",
    "                # the same for some values.\n",
    "                out_label = self._relabel(out_label.copy()).astype(np.float32)\n",
    "        elif AorB == 'B':\n",
    "             out_volume = crop_volume(\n",
    "                self.volume_B[pos[0]], vol_size, pos[1:])\n",
    "        return pos, out_volume, out_label\n",
    "    #######################################################\n",
    "    # Utils\n",
    "    #######################################################\n",
    "    def _assert_valid_shape(self):\n",
    "        assert all(\n",
    "            [(self.sample_volume_size <= x).all()\n",
    "             for x in self.volume_size_A]\n",
    "        ), \"Input size should be smaller than volume size.\"\n",
    "\n",
    "        assert all(\n",
    "            [(self.sample_volume_size <= x).all()\n",
    "             for x in self.volume_size_B]\n",
    "        ), \"Input size should be smaller than volume size.\"\n",
    "\n",
    "        if self.label is not None:\n",
    "            assert all(\n",
    "                [(self.sample_label_size <= x).all()\n",
    "                 for x in self.volume_size_A]\n",
    "            ), \"Label size should be smaller than volume size.\"\n",
    "\n",
    "    \n",
    "    def _relabel(self, seg, do_type=False):\n",
    "        # get the unique labels\n",
    "        uid = np.unique(seg)\n",
    "        # ignore all-background samples\n",
    "        if len(uid) == 1 and uid[0] == 0:\n",
    "            return seg\n",
    "\n",
    "        uid = uid[uid > 0]\n",
    "        mid = int(uid.max()) + 1  # get the maximum label for the segment\n",
    "\n",
    "        # create an array from original segment id to reduced id\n",
    "        m_type = seg.dtype\n",
    "        if do_type:\n",
    "            m_type = getSegType(mid)\n",
    "        mapping = np.zeros(mid, dtype=m_type)\n",
    "        mapping[uid] = np.arange(1, len(uid) + 1, dtype=m_type)\n",
    "        return mapping[seg.astype(np.int64)]\n",
    "\n",
    "    def _normalize(self, vol):\n",
    "        # normalize intput to -1 to 1 and convert to float32 \n",
    "        return ((vol / 255.0) * 2.0 - 1.0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size required for the augmentor: [17 97 97]\n",
      "Sample size required for the augmentor: [17 97 97]\n",
      "self.volume_A.shape  (1, 68, 1105, 1235)\n",
      "self.label.shape  (1, 68, 1105, 1235)\n",
      "self.volume_B.shape  (1, 255, 455, 455)\n",
      "Total number of samples to be generated for A:  56892108\n",
      "Total number of samples to be generated for B:  26502471\n"
     ]
    }
   ],
   "source": [
    "dataset = CerberusDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_216094/64369824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_216094/994947779.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    203\u001b[0m                     'valid_mask': None}\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0maugmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mout_volume_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmented\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmented\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/leander/cerberus/pytorch_connectomics/connectomics/data/augmentation/composition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sample, random_state)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mran\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# crop the data to the specified input size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/leander/cerberus/pytorch_connectomics/connectomics/data/augmentation/rotation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sample, random_state)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madditional_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'set' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "a = np.asarray((dataset.__getitem__(random.randint(1,400))[\"A\"]))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 17, 97, 97)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b68d5046490>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "label = np.asarray((dataset.__getitem__(random.randint(1,400))[\"Label\"]))\n",
    "                    \n",
    "print(label.shape)\n",
    "\n",
    "mask = np.asarray((label))[:1,15,:,:]\n",
    "cont = np.asarray((label))[1:2,15,:,:]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1)\n",
    "axes[0].imshow(mask[0])\n",
    "axes[1].imshow(cont[0])\n",
    "axes[2].imshow(np.asarray((label))[2,15,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 17, 65, 65]) torch.Size([1, 17, 65, 65]) torch.Size([1, 17, 65, 65])\n",
      "torch.Size([3, 17, 65, 65])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "label = torch.tensor(label)\n",
    "label_m = label[:1,:,:,:]\n",
    "label_c = label[1:2,:,:,:]\n",
    "label_d = label[2:3,:,:,:]\n",
    "print(label_m.shape, label_c.shape, label_d.shape)\n",
    "\n",
    "label_new = torch.cat((label_m, label_c, label_d), axis=0)\n",
    "print(label_new.shape)\n",
    "\n",
    "print((label==label_new).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.squeeze(np.asarray((dataset.__getitem__(random.randint(1,400))[\"Label\"])))\n",
    "a = np.asarray([[[1,32,34,423,222222222]]]).astype(np.uint16)\n",
    "print(a.dtype in [\"uint8\", \"flaot16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3664   5481  12217  25414  28971  32380  44118  45052  65757  84153\n",
      "  91040 123290 130231 138929 139288 140256 143553 147078 149919 151541\n",
      " 154011 154242 155442 156006 156950 158419 159972 161794 163555 164302\n",
      " 164555 165078 165434 165539]\n",
      "self.erosion_rates  None\n",
      "The binary and contour mask have to be normalized between 0.0 and 1.0 and not 0.0 and 34.0\n",
      "The binary and contour mask have to be normalized between 0.0 and 1.0 and not 0.0 and 34.0\n",
      "The binary and contour mask have to be normalized between 0.0 and 1.0 and not 0.0 and 34.0\n",
      "hiiiii\n",
      "The binary and contour mask have to be normalized between 0.0 and 1.0 and not False and True\n",
      "byyy\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18217/1836989102.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18217/103890899.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self.erosion_rates \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merosion_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The binary and contour mask have to be normalized between 0.0 and 1.0 and not {np.min(out_label)} and {np.max(out_label)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seg_to_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merosion_rates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The binary and contour mask have to be normalized between 0.0 and 1.0 and not {np.min(label)} and {np.max(label)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"The binary and contour mask have to be normalized between 0.0 and 1.0 and not {np.min(label)} and{np.max(label)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18217/103890899.py\u001b[0m in \u001b[0;36m_seg_to_targets\u001b[0;34m(self, label_orig, topts, erosion_rates, dilation_rates)\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target option %s is not valid!\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"byyy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The binary and contour mask have to be normalized between 0.0 and 1.0 and not {np.min(out)} and {np.max(out)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3_torch/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2828\u001b[0m     \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2829\u001b[0m     \"\"\"\n\u001b[0;32m-> 2830\u001b[0;31m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0m\u001b[1;32m   2831\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3_torch/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "for i, d in enumerate(iter(dataset)):\n",
    "    data=d\n",
    "    if i == 1:\n",
    "        break\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(None)\n",
    "a = None\n",
    "print(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
